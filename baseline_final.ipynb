{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Vf_qsIymil4E"
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from timm import create_model  # 최신 모델 로드\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from albumentations import CoarseDropout\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0SOQOqguim1T"
   },
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'IMG_SIZE': 224,\n",
    "    'EPOCHS': 10,\n",
    "    'LEARNING_RATE': 3e-4,\n",
    "    'BATCH_SIZE': 32,\n",
    "    'SEED': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "13LnOv4fio5T"
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(CFG['SEED'])\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "bjV-YFViirP1"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('./train.csv')\n",
    "train, val, _, _ = train_test_split(df, df['label'], test_size=0.3, stratify=df['label'], random_state=CFG['SEED'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "train['label'] = le.fit_transform(train['label'])\n",
    "val['label'] = le.transform(val['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "q2g9vqpUixJ3"
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, img_paths, labels=None, transform=None):\n",
    "        self.img_paths = img_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img = Image.open(self.img_paths[index]).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            img = np.array(img)\n",
    "            img = self.transform(image=img)['image']\n",
    "        if self.labels is not None:\n",
    "            return img, self.labels[index]\n",
    "        return img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_paths)\n",
    "\n",
    "# Data Augmentation\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=15, p=0.5),\n",
    "    A.OneOf([\n",
    "        A.CoarseDropout(max_holes=8, max_height=16, max_width=16, p=0.5),\n",
    "    ], p=0.5),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "    A.Resize(CFG['IMG_SIZE'], CFG['IMG_SIZE']),\n",
    "    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "train_dataset = CustomDataset(train['img_path'].values, train['label'].values, train_transform)\n",
    "val_dataset = CustomDataset(val['img_path'].values, val['label'].values, val_transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "9naCeBAtixZv"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c27763aa3f8a439987ddc7bd8b88c253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/791M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\Janus\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--timm--convnext_large.fb_in22k_ft_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "567245380be7463ab5260dc7e4a036f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/788M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\anaconda3\\envs\\Janus\\lib\\site-packages\\huggingface_hub\\file_download.py:147: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\USER\\.cache\\huggingface\\hub\\models--timm--swin_large_patch4_window7_224.ms_in22k_ft_in1k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "source": [
    "def build_model(model_name, num_classes):\n",
    "    model = create_model(model_name, pretrained=True, num_classes=num_classes)\n",
    "    return model.to(device)\n",
    "\n",
    "model_names = ['convnext_large', 'swin_large_patch4_window7_224']\n",
    "models_to_train = [build_model(name, num_classes=len(le.classes_)) for name in model_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "cghOn3zttLDi"
   },
   "outputs": [],
   "source": [
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        CE_loss = nn.CrossEntropyLoss()(inputs, targets)\n",
    "        pt = torch.exp(-CE_loss)\n",
    "        focal_loss = self.alpha * (1 - pt) ** self.gamma * CE_loss\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iIwyhAodi0gZ"
   },
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, scheduler, train_loader, val_loader, device):\n",
    "    criterion = FocalLoss()\n",
    "    best_model = None\n",
    "    best_score = 0\n",
    "\n",
    "    for epoch in range(CFG['EPOCHS']):\n",
    "        model.train()\n",
    "        for imgs, labels in tqdm(train_loader):\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        val_loss, val_score = validate_model(model, val_loader, device)\n",
    "        print(f\"Epoch {epoch+1}: Val Loss = {val_loss:.4f}, Val F1 Score = {val_score:.4f}\")\n",
    "        if val_score > best_score:\n",
    "            best_score = val_score\n",
    "            best_model = model\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    return best_model\n",
    "\n",
    "def validate_model(model, loader, device):\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    preds, true_labels = [], []\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs, labels = imgs.to(device), labels.to(device)\n",
    "            outputs = model(imgs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            preds.extend(outputs.argmax(dim=1).cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    f1 = f1_score(true_labels, preds, average='macro')\n",
    "    return val_loss / len(loader), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KCAsOzUMi3Qy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 347/347 [4:05:07<00:00, 42.38s/it]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Loss = 0.2371, Val F1 Score = 0.9319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 306/347 [4:09:41<31:18, 45.81s/it]  "
     ]
    }
   ],
   "source": [
    "trained_models = []\n",
    "for model in models_to_train:\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=CFG['LEARNING_RATE'])\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2)\n",
    "    best_model = train_model(model, optimizer, scheduler, train_loader, val_loader, device)\n",
    "    trained_models.append(best_model)\n",
    "\n",
    "# Ensemble Prediction (Weighted Voting)\n",
    "def weighted_voting(models, weights, loader, device):\n",
    "    ensemble_preds = []\n",
    "    for model, weight in zip(models, weights):\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for imgs in tqdm(loader):\n",
    "                imgs = imgs.to(device)\n",
    "                outputs = model(imgs).softmax(dim=1) * weight\n",
    "                preds.append(outputs.cpu().numpy())\n",
    "        ensemble_preds.append(np.vstack(preds))\n",
    "    return np.sum(ensemble_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wx9gF6vPi9oE"
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('./test.csv')\n",
    "test_dataset = CustomDataset(test['img_path'].values, None, val_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KCuDqsUsjB__"
   },
   "outputs": [],
   "source": [
    "weights = [0.4, 0.3, 0.3]  # Assign weights to models based on validation performance\n",
    "predictions = weighted_voting(trained_models, weights, test_loader, device)\n",
    "final_preds = predictions.argmax(axis=1)\n",
    "final_preds = le.inverse_transform(final_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xjIvpSN_jDOf"
   },
   "outputs": [],
   "source": [
    "# Submission\n",
    "submission = pd.read_csv('./sample_submission.csv')\n",
    "submission['label'] = final_preds\n",
    "submission.to_csv('./ensemble_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Janus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
